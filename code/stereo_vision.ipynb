{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount your Google drive (to access data)"
      ],
      "metadata": {
        "id": "v1hCAYvxI0dB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzq_HnwpHXQ6",
        "outputId": "4dbfe344-f384-41bb-e5f7-e1a4fc69dfa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/NWU/3DV_basics\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Go to target directory\n",
        "%cd /content/drive/MyDrive/NWU/3DV_basics/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include required packages before using them"
      ],
      "metadata": {
        "id": "TNAat_eCIpFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # for processing images\n",
        "import numpy as np # for matrix manipulation\n",
        "import glob # for accessing path\n",
        "import matplotlib.pyplot as plt # for general visualization\n",
        "import plot # custom visualization\n",
        "import copy\n",
        "import yaml # for loading yaml files"
      ],
      "metadata": {
        "id": "GKrhQ26VI6W9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "h6n2EfEZN3Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_camera_data(filename):\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            data = yaml.safe_load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {filename} not found.\")\n",
        "        return None\n",
        "\n",
        "    # Intrinsic parameters\n",
        "    K = np.array(data[\"camera_intrinsic_K\"], dtype=np.float64)\n",
        "\n",
        "    # Distortion coefficient\n",
        "    D = np.array(data[\"distortion_coeffs_D\"], dtype=np.float64).reshape(-1, 1)\n",
        "\n",
        "    return K, D\n",
        "\n",
        "# Read Image\n",
        "img_left = cv2.imread('./data/stereo_001_rescale.png', cv2.IMREAD_COLOR_RGB) #left image\n",
        "img_right = cv2.imread('./data/stereo_002_rescale.png', cv2.IMREAD_COLOR_RGB) #right image\n",
        "\n",
        "# if images are not found\n",
        "if img_left is None or img_right is None:\n",
        "    print(\"Error: Could not load images.\")\n",
        "    exit()\n",
        "\n",
        "# Get camera data\n",
        "K, D = load_camera_data('camera_info.yaml')\n",
        "image_size = img_left.shape[::-1] # (width, height)\n",
        "\n",
        "print(f\"Intrinsic paramters K:\\n {K}\\n\\n Distortion coefficients:\\n {D}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1VKtcqyN53v",
        "outputId": "92d4e5e3-e48e-4f78-f38b-bfb934b2f8ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intrinsic paramters K:\n",
            " [[350.    0.  214. ]\n",
            " [  0.  350.  285.5]\n",
            " [  0.    0.    1. ]]\n",
            "\n",
            " Distortion coefficients:\n",
            " [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Extrinsic Calibration (Relative Pose Estimation)\n",
        "\n",
        "**INPUT:**\n",
        "* 2 images containing a checkerboard\n",
        "* Intrinsic parameters **K**, Distortion Coefficients **D**\n",
        "\n",
        "**OUTPUT:**\n",
        "* Relative Rotation Matrix **R_2to1 (3x3)**\n",
        "* Relative Translation Vector **T_2to1 (3x1)**"
      ],
      "metadata": {
        "id": "_kl2kLB-ODmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calibration(img_left, img_right, K, D, image_size, checkerboard_size):\n",
        "    \"\"\"Compute relative pose from Camera 2 to Camera 1.\"\"\"\n",
        "\n",
        "    # ...Your code goes from here....\n",
        "    # a. Define 3D coordinates of checkerboard (object points)\n",
        "\n",
        "\n",
        "    # b. Detect 2D checkerboard corners in images (image points)\n",
        "    # .... Please also visualize the detected corners using cv2.drawChessboardCorners()\n",
        "\n",
        "    # c. Estimate relative poses from world to camera 1 (R_wto1, T_wto1)\n",
        "    #    and world to camera 2 (R_wto2, T_wto2) using cv2.solvePnP()\n",
        "    # ....remember to convert from rotation vector to 3x3 rotation matrix using cv2.Rodrigues()\n",
        "\n",
        "\n",
        "    # d. Use [R_wto1, T_wto1] and [R_wto2, T_wto2] to compute the relative pose\n",
        "    #    from camera 2 to 1: R_2to1, T_2to1\n",
        "\n",
        "\n",
        "    return R_2to1, T_2to1"
      ],
      "metadata": {
        "id": "pU-lJZK_OXaQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_2to1, T_2to1 = calibration(img_left, img_right, K, D, image_size, checkerboard_size=(3, 4))\n",
        "\n",
        "# Visualize the cameras in 3D Space\n",
        "plot.plot_cameras_with_points([np.eye(3), R_2to1], [np.zeros((3, 1)), T_2to1], K, points3D=None, colors=None)"
      ],
      "metadata": {
        "id": "pmb-lxNxOgJM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Image Rectification\n",
        "\n",
        "**INPUT:**\n",
        "* 2 images: img_left, img_right\n",
        "* Intrinsic parameters **K**\n",
        "* Relative Pose: **R_2to1 (3x3), T_2to1 (3x1)**\n",
        "\n",
        "**OUTPUT:**\n",
        "* Rectified Images: **rectified_L, rectified_R**"
      ],
      "metadata": {
        "id": "gFJ9Qt8USy7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rectify_images(img_left, img_right, K, R_2to1, T_2to1):\n",
        "    \"\"\"Make the two images 'horizontally aligned' \"\"\"\n",
        "\n",
        "    # ...Your code goes from here....\n",
        "    # a. Define new camera axes R_rec\n",
        "\n",
        "\n",
        "    # b. Compute the Homograpy matrices: H_1, H_2\n",
        "\n",
        "\n",
        "    # c. Warp the images: rectified_L, rectified_R\n",
        "\n",
        "\n",
        "    return R_rec, rectified_L, rectified_R"
      ],
      "metadata": {
        "id": "n4dbIVb0NfDg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_rec, rectified_L, rectified_R = rectify_images(img_left, img_right, K, R_2to1, T_2to1)\n",
        "\n",
        "# Visualization\n",
        "plot.plotfigure([img_left, img_right], title='Original images')\n",
        "plot.plotfigure([rectified_L, rectified_R], title='Rectified images')"
      ],
      "metadata": {
        "id": "pdcwZv0KIpg0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Correspondence Search (Disparity Map)\n",
        "\n",
        "**INPUT:**\n",
        "* Rectified Images: rectified_L, rectified_R\n",
        "\n",
        "**OUTPUT:**\n",
        "* Disparity Map"
      ],
      "metadata": {
        "id": "CaFqYaUmTGhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_disparity_map(rectified_L, rectified_R):\n",
        "    \"\"\"Computes the pixel shift (disparity).\"\"\"\n",
        "\n",
        "    # ...Your code goes from here....\n",
        "    # using cv2.StereoSGBM_create()\n",
        "    #----------------------------------\n",
        "    # SGBM params = {\n",
        "        # minDisparity = 10 # far\n",
        "        # numDisparities = 128 # close -> detectable depth range, must be divisible by 16\n",
        "        # blockSize = 5 # odd num, between 3 and 11\n",
        "        # P1 = 8 * 1 * blockSize**2 # smoothness control: P2 > P1\n",
        "        # P2 = 32 * 1 * blockSize**2\n",
        "        # disp12MaxDiff=1,      # Maximum difference between left/right disparity check\n",
        "        # uniquenessRatio=15,   # Margin in percentage by which the best cost should beat the second best\n",
        "        # speckleWindowSize=150,# Window size for speckle elimination\n",
        "        # speckleRange=32, # Maximum disparity variation in a connected component\n",
        "    #}\n",
        "    #----------------------------------\n",
        "\n",
        "    # a. Initialize the SGBM matcher\n",
        "\n",
        "\n",
        "    # b. Compute disparity -> 16-bit signed int\n",
        "\n",
        "\n",
        "    # c. Convert to float (astype(np.float32)) and scale (divided by 16.0) for visualization\n",
        "\n",
        "\n",
        "    # d. Filter out invalid values\n",
        "\n",
        "\n",
        "    return disparity_map"
      ],
      "metadata": {
        "id": "XMYvKMCTTGLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disparity_map = compute_disparity_map(rectified_L, rectified_R)\n",
        "\n",
        "# Visualization\n",
        "plt.imshow(disparity_map)\n",
        "plt.colorbar() # show the scale\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r5a88toZWFiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Depth Estimation\n",
        "\n",
        "**INPUT:**\n",
        "* Disparity Map\n",
        "* Intrinsic K\n",
        "* Relative Translation vector T_2to1\n",
        "\n",
        "**OUTPUT:**\n",
        "* Depth Map"
      ],
      "metadata": {
        "id": "BEgZsQzrXASF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disparity_to_depth(disparity_map, K, T_2to1, mask=None):\n",
        "  \"\"\"Computes depth from disparity.\"\"\"\n",
        "\n",
        "  # ...Your code goes from here....\n",
        "\n",
        "  # a. Get the focal length and the length of baseline (i.e., length of T_2to1)\n",
        "\n",
        "\n",
        "  # b. Compute depth from disparity\n",
        "\n",
        "\n",
        "  # c. Filter out invalid depths, e.g., too far or too close\n",
        "\n",
        "\n",
        "  return depth_map"
      ],
      "metadata": {
        "id": "O6roowoMW_4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth_map = disparity_to_depth(disparity_map, K, T_2to1)\n",
        "\n",
        "# Visualization\n",
        "plt.imshow(depth_map, cmap='jet')\n",
        "plt.colorbar() # show the scale\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1WuhvJViYD2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Depth to 3D point cloud\n",
        "\n",
        "**INPUT:**\n",
        "* Depth Map\n",
        "* Intrinsic **K**, New camera axes **R_rec**\n",
        "* (rectified_L $\\rightarrow$ for accessing colors)\n",
        "\n",
        "**OUTPUT:**\n",
        "* 3D colored point cloud"
      ],
      "metadata": {
        "id": "FagJZ4WfYmfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def depth_to_pointcloud3D(depth_map, K, R_rec, rectified_L):\n",
        "  \"\"\"Computes 3D point cloud from depth.\"\"\"\n",
        "\n",
        "  # ...Your code goes from here....\n",
        "\n",
        "  # a. Prepare 2d image coordinate matrix -> (u, v, 1)\n",
        "\n",
        "\n",
        "  # b. Transform to camera space using inverse of K\n",
        "\n",
        "\n",
        "  # c. Multiply depth Z\n",
        "\n",
        "\n",
        "  # d. Assign color for each point\n",
        "\n",
        "\n",
        "  # e. Transform back to original camera 1 frame using the transpose of R_rec\n",
        "\n",
        "\n",
        "  return point_cloud3D, colors"
      ],
      "metadata": {
        "id": "EAYVJgJaYlqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_cloud3D, colors = depth_to_pointcloud3D(depth_map, K, R_rec, rectified_L)\n",
        "\n",
        "# Visualize the 3D colored point cloud and cameras in 3D Space\n",
        "plot.plot_cameras_with_points([np.eye(3), R_2to1], [np.zeros((3, 1)), T_2to1], K, points3D=point_cloud3D, colors=colors)"
      ],
      "metadata": {
        "id": "H6iz2RvlbRAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}